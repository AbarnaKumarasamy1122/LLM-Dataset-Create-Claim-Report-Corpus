import os
import json
import pandas as pd

# ---------------------------------------------
# ğŸ—‚ Path Setup (auto-detects JSONL folder)
# ---------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.normpath(os.path.join(BASE_DIR, "..", "data"))

# Prefer llm_jsonl folder if it exists
JSONL_DIR = os.path.join(DATA_DIR, "llm_jsonl")
if not os.path.exists(JSONL_DIR):
    JSONL_DIR = DATA_DIR  # fallback if files saved directly in /data

ENRICHED_PATH = os.path.join(DATA_DIR, "enriched_metadata.csv")
REPORTS_DIR = os.path.join(DATA_DIR, "reports")
TRAIN_PATH = os.path.join(JSONL_DIR, "train.jsonl")
VAL_PATH = os.path.join(JSONL_DIR, "val.jsonl")
TEST_PATH = os.path.join(JSONL_DIR, "test.jsonl")

print("ğŸ” Running Sanity Checks for Week 4 Dataset...\n")

# ---------------------------------------------
# ğŸ§  Helper: Validate JSONL file structure
# ---------------------------------------------
def check_jsonl_file(path):
    if not os.path.exists(path):
        print(f"âŒ Missing file: {path}")
        return 0

    print(f"ğŸ” Checking {os.path.basename(path)} ...")
    valid, invalid = 0, 0
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            try:
                obj = json.loads(line)
                if "input" in obj and "output" in obj:
                    valid += 1
                else:
                    invalid += 1
            except json.JSONDecodeError:
                invalid += 1

    print(f"âœ… Valid: {valid}, âš ï¸ Invalid: {invalid}\n")
    return valid

# ---------------------------------------------
# 1ï¸âƒ£ Check Enriched Metadata
# ---------------------------------------------
print(f"ğŸ“‹ Checking metadata file: {ENRICHED_PATH}")

if not os.path.exists(ENRICHED_PATH):
    print("âŒ enriched_metadata.csv not found.")
    df = None
else:
    df = pd.read_csv(ENRICHED_PATH)
    print(f"âœ… Loaded {len(df)} rows")

    required_cols = [
        "image_id", "shipment_id", "damage_type",
        "severity", "damage_area_pct", "likely_cause",
        "liability", "estimated_cost", "action"
    ]
    missing_cols = [c for c in required_cols if c not in df.columns]
    if missing_cols:
        print(f"âŒ Missing columns: {missing_cols}")
    else:
        print("âœ… All required columns present")

    # Check for nulls
    nulls = df.isnull().sum()
    nulls = nulls[nulls > 0]
    if len(nulls) > 0:
        print("âš ï¸ Null values found:")
        print(nulls)
        # Optional: auto-fill missing liability
        if "liability" in nulls.index:
            df["liability"] = df["liability"].fillna("Pending Assessment")
            df.to_csv(ENRICHED_PATH, index=False)
            print("ğŸ©¹ Filled missing 'liability' with 'Pending Assessment'")
    else:
        print("âœ… No null values")

    # Check for duplicate image_ids
    duplicate_ids = df[df["image_id"].duplicated(keep=False)]["image_id"].unique()
    if len(duplicate_ids) > 0:
        print(f"âš ï¸ Duplicate image_ids found: {len(duplicate_ids)}")
        dup_log = os.path.join(DATA_DIR, "duplicate_image_ids.csv")
        df[df["image_id"].isin(duplicate_ids)].to_csv(dup_log, index=False)
        print(f"ğŸ“ Duplicates logged at: {dup_log}")
    else:
        print("âœ… No duplicate image_ids")

# ---------------------------------------------
# 2ï¸âƒ£ Check Reports Folder
# ---------------------------------------------
print(f"\nğŸ§¾ Checking reports folder: {REPORTS_DIR}")

if not os.path.exists(REPORTS_DIR):
    print("âŒ Reports folder missing!")
else:
    report_files = [f for f in os.listdir(REPORTS_DIR) if f.endswith(".txt") or f.endswith(".jsonl") or f.endswith(".json")]
    print(f"âœ… Found {len(report_files)} report files")

    if len(report_files) > 0:
        empty_reports = [rf for rf in report_files if os.path.getsize(os.path.join(REPORTS_DIR, rf)) == 0]
        if len(empty_reports) > 0:
            print(f"âš ï¸ Empty reports found: {len(empty_reports)}")
        else:
            print("âœ… No empty reports")
    else:
        print("â„¹ï¸ No individual report files detected (may be combined in claim_reports.jsonl)")

# ---------------------------------------------
# 3ï¸âƒ£ Check JSONL Datasets
# ---------------------------------------------
print("\nğŸ” Checking JSONL files...")
train_valid = check_jsonl_file(TRAIN_PATH)
val_valid = check_jsonl_file(VAL_PATH)
test_valid = check_jsonl_file(TEST_PATH)

# ---------------------------------------------
# ğŸ“Š Summary
# ---------------------------------------------
print("\nğŸ“Š Sanity Check Summary:")
print(f"   Enriched metadata rows: {len(df) if df is not None else 'N/A'}")
print(f"   Valid train records: {train_valid}")
print(f"   Valid val records: {val_valid}")
print(f"   Valid test records: {test_valid}")

print("\nğŸ¯ Sanity checks complete.")
